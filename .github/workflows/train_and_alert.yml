name: "üß† Crypto AI Hybrid v13.8 - Fetch ‚Üí Train ‚Üí Spike ‚Üí Alert"

on:
  schedule:
    - cron: "*/30 * * * *"   # Every 30 minutes
  workflow_dispatch:

permissions:
  contents: write
  actions: read

env:
  PYTHONUNBUFFERED: "1"

jobs:
  crypto-ai:
    runs-on: ubuntu-latest

    steps:
      # ---------------------------
      # 1Ô∏è‚É£ Setup and Checkout
      # ---------------------------
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # ---------------------------
      # üß∞ Install dependencies (with cache)
      # ---------------------------
      - name: üíæ Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          echo "[SETUP] Installing Python dependencies..."
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true
          pip install yfinance pandas numpy scikit-learn requests joblib matplotlib seaborn pycoingecko ccxt

      # ---------------------------
      # 2Ô∏è‚É£ Prepare required folders
      # ---------------------------
      - name: üóÇ Prepare required folders
        run: |
          echo "[INIT] Ensuring all required folders exist..."
          mkdir -p models data_cache telemetry_logs utils training_summary models/spike_trend

      # ---------------------------
      # 3Ô∏è‚É£ Run Multi-Source Data Fetcher
      # ---------------------------
      - name: üì¶ Run Multi-Source Data Fetcher
        run: |
          echo "[RUN] Fetching crypto data..."
          if [ -f "utils/data_fetcher.py" ]; then
            python utils/data_fetcher.py || { echo "[‚ùå ERROR] Data fetch failed."; exit 1; }
          elif [ -f "data_fetcher.py" ]; then
            python data_fetcher.py || { echo "[‚ùå ERROR] Root-level fetch failed."; exit 1; }
          else
            echo "[‚ùå ERROR] data_fetcher.py not found!"
            exit 1
          fi
          echo "[INFO] Data cache created:"
          ls -lh data_cache || echo "[WARN] No cache created."

      # ---------------------------
      # 4Ô∏è‚É£ Check model freshness
      # ---------------------------
      - name: ‚è± Check model freshness
        id: freshness
        run: |
          echo "[CHECK] Checking if models are older than 2 hours..."
          mkdir -p models
          needs_training=false

          for pair in BTCUSDT XRPUSDT GALAUSDT; do
            model="models/${pair}_model.pkl"
            if [ -f "$model" ]; then
              age_seconds=$(( $(date +%s) - $(stat -c %Y "$model") ))
              echo "[INFO] $model age: ${age_seconds}s"
              if [ $age_seconds -gt 7200 ]; then
                echo "[WARN] $model older than 2 hours ‚Äî retraining required."
                needs_training=true
              fi
            else
              echo "[WARN] Missing model for $pair ‚Äî retraining required."
              needs_training=true
            fi
          done

          echo "needs_training=$needs_training" >> $GITHUB_ENV
          echo "[RESULT] Training needed: $needs_training"

      # ---------------------------
      # 5Ô∏è‚É£ Train AI Models Conditionally
      # ---------------------------
      - name: üß† Train AI Models
        if: env.needs_training == 'true'
        run: |
          echo "[TRAIN] Starting model training..."
          python train_ai_model.py || echo "[WARN] Training script encountered an issue."

      - name: ‚úÖ Skip Training (Models Fresh)
        if: env.needs_training == 'false'
        run: echo "[INFO] Models are fresh (<2h). Skipping training."

      # ---------------------------
      # 6Ô∏è‚É£ Run Spike Predictor
      # ---------------------------
      - name: ‚ö° Run Spike Predictor
        run: |
          echo "[RUN] Executing spike predictor..."
          if [ -f "spike_predictor.py" ]; then
            python spike_predictor.py || echo "[WARN] Spike predictor exited with non-zero status."
          else
            echo "[‚ùå ERROR] spike_predictor.py not found!"
          fi
          echo "[INFO] Spike packs in models/spike_trend:"
          ls -lh models/spike_trend || echo "[WARN] No spike packs found."

      # ---------------------------
      # 7Ô∏è‚É£ Run Crypto AI Alert Logic (v11)
      # ---------------------------
      - name: üö® Run Crypto AI Alert Logic (v11)
        env:
          TELEGRAM_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          EMAIL_HOST: ${{ secrets.EMAIL_HOST }}
          EMAIL_PORT: ${{ secrets.EMAIL_PORT }}
          EMAIL_USERNAME: ${{ secrets.EMAIL_USERNAME }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
        run: |
          echo "[RUN] Executing crypto alert logic..."
          if [ -f "crypto_ai_alert_v10.py" ]; then
            python crypto_ai_alert_v10.py || echo "[WARN] Alert logic exited with non-zero status."
          else
            echo "[‚ùå ERROR] crypto_ai_alert_v10.py not found!"
          fi

      # ---------------------------
      # 8Ô∏è‚É£ Upload Trained Models
      # ---------------------------
      - name: üíæ Upload Trained Models
        uses: actions/upload-artifact@v4
        with:
          name: trained_models
          path: models/
          retention-days: 7

      # ---------------------------
      # 9Ô∏è‚É£ Upload Telemetry Logs
      # ---------------------------
      - name: üßπ Clean Telemetry Logs (includes spike summaries)
        run: |
          echo "[CLEANUP] Starting telemetry cleanup..."
          if [ -d "telemetry_logs" ]; then
            echo "[INFO] Removing old spike_train_summar* files..."
            find telemetry_logs -type f -name "spike_train_summar*" -exec rm -f {} \;
            echo "[INFO] Running telemetry_cleanup.py for log retention..."
            python3 telemetry_cleanup.py || echo "[WARN] Cleanup script failed, continuing..."
            echo "[DONE] Telemetry cleanup complete ‚Äî includes spike summary trimming."
          else
            echo "[INFO] telemetry_logs directory not found, skipping cleanup."
          fi

      - name: üìä Upload Telemetry Logs
        uses: actions/upload-artifact@v4
        with:
          name: telemetry_logs
          path: telemetry_logs/
          retention-days: 7

      # ---------------------------
      # üîÅ Cache & Artifact Cleanup
      # ---------------------------
      - name: üßπ Prune old pip caches (keep latest 1)
        if: ${{ github.ref == 'refs/heads/main' }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "[CLEANUP] Pruning pip caches..."
          gh cache list --sort created-at --order desc --limit 50 --json id,key \
            --jq '. | map(select(.key | contains("pip"))) | .[1:] | .[].id' | while read cache_id; do
              echo "[DELETE] Removing old pip cache $cache_id"
              gh cache delete $cache_id || true
            done
          echo "[DONE] Retained latest pip cache only."

      - name: üßΩ Cleanup old workflow artifacts (keep last 2)
        if: ${{ github.ref == 'refs/heads/main' }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "[CLEANUP] Removing old workflow artifacts..."
          gh run list --limit 50 --json databaseId --jq '.[2:] | .[].databaseId' | while read run_id; do
            echo "[DELETE] Removing old workflow run $run_id"
            gh run delete $run_id || true
          done
          echo "[DONE] Retained last 2 workflow artifacts only."

      # ---------------------------
      # 11Ô∏è‚É£ Commit and Push Models + Telemetry
      # ---------------------------
      - name: ü™∂ Commit and Push Models + Telemetry
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "[GIT] Saving models and telemetry logs..."
          git config user.email "actions@github.com"
          git config user.name "github-actions[bot]"
          git add -f models/*.pkl models/spike_trend/*.pkl telemetry_logs/*.json data_cache/* training_summary/* || true
          if git diff --cached --quiet; then
            echo "[INFO] No changes detected, skipping commit."
          else
            git commit -m "ü§ñ Auto-update: Models + Telemetry ($(date '+%Y-%m-%d %H:%M:%S'))"
            git pull --rebase origin main || echo "[WARN] Rebase skipped or failed."
            git push origin main || echo "[WARN] Push failed (check permissions)."
          fi

      # ---------------------------
      # ‚úÖ Finish
      # ---------------------------
      - name: ‚úÖ Done
        run: echo "[FINISH] Crypto AI Hybrid v13.8 workflow completed successfully."
