name: "üß† Crypto AI Hybrid v13.8 - Fetch ‚Üí Train ‚Üí Spike ‚Üí Alert"

on:
  schedule:
    - cron: "*/30 * * * *"   # Every 30 minutes
  workflow_dispatch:

permissions:
  contents: write
  actions: write   # ‚úÖ needed for deleting old runs/artifacts

env:
  PYTHONUNBUFFERED: "1"

jobs:
  crypto-ai:
    runs-on: ubuntu-latest

    steps:
      # ---------------------------
      # 1Ô∏è‚É£ Setup and Checkout
      # ---------------------------
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # ---------------------------
      # üß∞ Install dependencies (with cache)
      # ---------------------------
      - name: üíæ Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-  # ‚úÖ keeps only 1 copy per OS hash

      - name: Install dependencies
        run: |
          echo "[SETUP] Installing Python dependencies..."
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true
          pip install yfinance pandas numpy scikit-learn requests joblib matplotlib seaborn pycoingecko ccxt

      # ---------------------------
      # 2Ô∏è‚É£ Prepare required folders
      # ---------------------------
      - name: üóÇ Prepare required folders
        run: |
          mkdir -p models data_cache telemetry_logs utils training_summary models/spike_trend

      # ---------------------------
      # 3Ô∏è‚É£ Run Multi-Source Data Fetcher
      # ---------------------------
      - name: üì¶ Run Multi-Source Data Fetcher
        run: |
          echo "[RUN] Fetching crypto data..."
          if [ -f "utils/data_fetcher.py" ]; then
            python utils/data_fetcher.py || { echo "[‚ùå ERROR] Data fetch failed."; exit 1; }
          elif [ -f "data_fetcher.py" ]; then
            python data_fetcher.py || { echo "[‚ùå ERROR] Root-level fetch failed."; exit 1; }
          else
            echo "[‚ùå ERROR] data_fetcher.py not found!"
            exit 1
          fi

      # ---------------------------
      # 4Ô∏è‚É£ Check model freshness
      # ---------------------------
      - name: ‚è± Check model freshness
        id: freshness
        run: |
          echo "[CHECK] Checking if models are older than 2 hours..."
          mkdir -p models
          needs_training=false

          for pair in BTCUSDT XRPUSDT GALAUSDT; do
            model="models/${pair}_model.pkl"
            if [ -f "$model" ]; then
              age_seconds=$(( $(date +%s) - $(stat -c %Y "$model") ))
              echo "[INFO] $model age: ${age_seconds}s"
              if [ $age_seconds -gt 7200 ]; then
                echo "[WARN] $model older than 2 hours ‚Äî retraining required."
                needs_training=true
              fi
            else
              echo "[WARN] Missing model for $pair ‚Äî retraining required."
              needs_training=true
            fi
          done

          echo "needs_training=$needs_training" >> $GITHUB_ENV

      # ---------------------------
      # 5Ô∏è‚É£ Train AI Models Conditionally
      # ---------------------------
      - name: üß† Train AI Models
        if: env.needs_training == 'true'
        run: python train_ai_model.py || echo "[WARN] Training script encountered an issue."

      - name: ‚úÖ Skip Training (Models Fresh)
        if: env.needs_training == 'false'
        run: echo "[INFO] Models are fresh (<2h). Skipping training."

      # ---------------------------
      # 6Ô∏è‚É£ Run Spike Predictor
      # ---------------------------
      - name: ‚ö° Run Spike Predictor
        run: |
          echo "[RUN] Executing spike predictor..."
          python spike_predictor.py || echo "[WARN] Spike predictor exited with non-zero status."
          echo "[INFO] Spike packs in models/spike_trend:"
          ls -lh models/spike_trend || echo "[WARN] No spike packs found."

      # ---------------------------
      # 7Ô∏è‚É£ Run Crypto AI Alert Logic (v11)
      # ---------------------------
      - name: üö® Run Crypto AI Alert Logic (v11)
        env:
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          EMAIL_HOST: ${{ secrets.EMAIL_HOST }}
          EMAIL_PORT: ${{ secrets.EMAIL_PORT }}
          EMAIL_USERNAME: ${{ secrets.EMAIL_USERNAME }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
        run: |
          python crypto_ai_alert_v10.py || echo "[WARN] Alert logic exited with non-zero status."

      # ---------------------------
      # 8Ô∏è‚É£ Upload Trained Models
      # ---------------------------
      - name: üíæ Upload Trained Models
        uses: actions/upload-artifact@v4
        with:
          name: trained_models
          path: models/
          retention-days: 7

      # ---------------------------
      # 9Ô∏è‚É£ Cleanup + Upload Telemetry Logs
      # ---------------------------
      - name: üßπ Remove old spike_train_summary files (keep last 3)
        run: |
          echo "[CLEANUP] Keeping last 3 spike_train_summary* files..."
          mkdir -p telemetry_logs
          find telemetry_logs -type f -name "spike_train_summar*" | sort -r | tail -n +4 | xargs -r rm -f
          echo "[DONE] Retained last 3 summaries."

      - name: üìä Upload Telemetry Logs
        uses: actions/upload-artifact@v4
        with:
          name: telemetry_logs
          path: telemetry_logs/
          retention-days: 7

      # ---------------------------
      # üîü üßπ Remove Old Workflow Runs (keep last 2)
      # ---------------------------
      - name: üß© Cleanup Cache & Old Workflow Artifacts
        if: github.ref == 'refs/heads/main'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "[CLEANUP] Removing old workflow artifacts (keep last 2)..."
          gh run list --limit 20 --json databaseId,status --jq '.[] | select(.status=="completed") | .databaseId' | tail -n +3 | while read run_id; do
            echo "[DELETE] Removing old workflow run $run_id"
            gh run delete $run_id || echo "[‚ö†Ô∏è Skip] Missing permission or already removed."
          done
          echo "[DONE] Kept last 2 workflow artifacts only."

      # ---------------------------
      # 11Ô∏è‚É£ Commit and Push Models + Telemetry
      # ---------------------------
      - name: ü™∂ Commit and Push Models + Telemetry
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.email "actions@github.com"
          git config user.name "github-actions[bot]"
          git add -f models/*.pkl models/spike_trend/*.pkl telemetry_logs/*.json data_cache/* training_summary/* || true
          if git diff --cached --quiet; then
            echo "[INFO] No changes detected, skipping commit."
          else
            git commit -m "ü§ñ Auto-update: Models + Telemetry ($(date '+%Y-%m-%d %H:%M:%S')) [skip ci]"
            git pull --rebase origin main || echo "[WARN] Rebase skipped or failed."
            git push origin main || echo "[WARN] Push failed (check permissions)."
          fi

      # ---------------------------
      # ‚úÖ Finish
      # ---------------------------
      - name: ‚úÖ Done
        run: echo "[FINISH] Crypto AI Hybrid v13.8 workflow completed successfully."
